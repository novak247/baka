{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference for Massage Robot Assistant in 4-bit Mode\n",
    "\n",
    "This notebook loads the merged model from the Hugging Face Hub using UnsloTH in 4-bit mode for fast inference and runs a test prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the training/inference prompt style and the test question\n",
    "train_prompt_style = \"\"\"Below is an instruction that describes a task for a massage robot, paired with an input that provides further context.\n",
    "Write a response that generates an executable pipeline in Python using only the provided functions.\n",
    "Before answering, analyze the task carefully and generate a clear sequence of commands.\n",
    "\n",
    "### Instruction:\n",
    "You are provided with high-level instructions for operating a massage robot. Create an executable pipeline in Python that structures task execution through a sub-task pipeline. This pipeline should be composed exclusively of the functions listed below in the Capabilities section, arranged in a logical and correct order so that it can be directly executed. Your response should only consist of the pipeline without additional information.\n",
    "\n",
    "Capabilities:\n",
    "    start() → Initializes the robot.\n",
    "    stop() → Stops the robot.\n",
    "    home() → Moves the robot to the home position.\n",
    "    [x, y, z] = detect_body_part(part_name) → Detects the specified body part and returns the coordinates.\n",
    "    move_to([x, y, z]) → Moves the robot to the specified coordinates.\n",
    "    change_force(mode, value) → Adjusts the massage force based on the specified mode:\n",
    "        - If mode is 'absolute', then value is any real number, setting the force directly.\n",
    "        - If mode is 'relative', then value is between -1 and 1, modifying the current force F as:\n",
    "          F_new = (1 + value) * F\n",
    "    automatic_massage(part_name) → Automatically massages the specified body part.\n",
    "\n",
    "### Question:\n",
    "{}\n",
    "\n",
    "### Response:\n",
    "{}\"\"\"\n",
    "\n",
    "# Test question\n",
    "question = \"up the pressure\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"HF_HUB_ENABLE_HF_TRANSFER\"] = \"0\"\n",
    "os.environ[\"HF_HUB_DISABLE_PROGRESS_BAR\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model and tokenizer from novak247/massage_assistant_v1_full in 4-bit mode...\n",
      "==((====))==  Unsloth 2025.2.12: Fast Llama patching. Transformers: 4.49.0.\n",
      "   \\\\   /|    GPU: NVIDIA GeForce RTX 4060 Ti. Max memory: 15.699 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 8.9. CUDA Toolkit: 12.4. Triton: 3.2.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.29.post3. FA2 = False]\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9ff81b4ed1146a4aed959e5ef7ee99f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6112d800f874d7eb71f448df8afb20a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model-00002-of-00004.bin:  18%|#7        | 891M/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91488a96480c4d61ad2c5c0f8ec15dd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model-00003-of-00004.bin:   0%|          | 0.00/4.92G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2b6cf1b5020476a9dad9af1151bc7f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model-00004-of-00004.bin:   0%|          | 0.00/1.17G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bb569143aa044d2a08b87a76f328174",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and tokenizer loaded.\n"
     ]
    }
   ],
   "source": [
    "# Load the model and tokenizer from Hugging Face Hub in 4-bit mode using UnsloTH\n",
    "from unsloth import FastLanguageModel\n",
    "\n",
    "# Replace with your model repository on the Hugging Face Hub\n",
    "model_repo = \"novak247/massage_assistant_v1_full\"\n",
    "\n",
    "print(\"Loading model and tokenizer from\", model_repo, \"in 4-bit mode...\")\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_repo,\n",
    "    load_in_4bit=True,\n",
    "    max_seq_length=2048\n",
    ")\n",
    "print(\"Model and tokenizer loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized inference mode enabled.\n"
     ]
    }
   ],
   "source": [
    "# Enable optimized inference mode\n",
    "FastLanguageModel.for_inference(model)\n",
    "print(\"Optimized inference mode enabled.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input prepared and moved to GPU.\n"
     ]
    }
   ],
   "source": [
    "# Prepare the input using the prompt style and tokenize the input, then move to GPU\n",
    "inputs = tokenizer([train_prompt_style.format(question, \"\")], return_tensors=\"pt\").to(\"cuda\")\n",
    "print(\"Input prepared and moved to GPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Response:\n",
      "\n",
      "Here's the pipeline for the task:\n",
      "\n",
      "```python\n",
      "pipeline = [\n",
      "    start(),\n",
      "    detect_body_part('shoulder'),\n",
      "    move_to([0, 0, 0.5]),\n",
      "    change_force('relative', 0.2),\n",
      "    automatic_massage('shoulder'),\n",
      "    home()\n",
      "]\n",
      "```\n",
      "\n",
      "### Explanation:\n",
      "The pipeline begins by initializing the robot with `start()`. Next, it detects the shoulder part with `detect_body_part('shoulder')`, which gives the coordinates. The robot then moves to the detected coordinates with `move_to()`. To adjust the pressure, it changes the force mode to 'relative' and increases it by 20% using `change_force('relative', 0.2)`. Finally, it performs the automatic massage on the shoulder and returns to the home position with `home()`.\n",
      "\n",
      "The response provided correctly structures the task execution through a logical sequence of functions, ensuring the robot performs the desired actions without errors.\n",
      "</think>\n",
      "\n",
      "To increase the pressure during the massage, the pipeline should adjust the force level appropriately before performing the automatic massage.\n",
      "\n",
      "```python\n",
      "pipeline = [\n",
      "    start(),\n",
      "    detect_body_part('shoulder'),\n",
      "    move_to([0, 0, 0.5]),\n",
      "    change_force('absolute', 0.8),\n",
      "    automatic_massage('shoulder'),\n",
      "    home()\n",
      "]\n",
      "```\n",
      "\n",
      "The pipeline:\n",
      "1. Starts the robot.\n",
      "2. Detects the shoulder coordinates.\n",
      "3. Moves the robot to the detected position.\n",
      "4. Sets the force to 0.8 using absolute mode.\n",
      "5. Automatically massages the shoulder with the adjusted force.\n",
      "6. Returns the robot to the home position.<｜end▁of▁sentence｜>\n"
     ]
    }
   ],
   "source": [
    "# Generate a response using the model\n",
    "outputs = model.generate(\n",
    "    input_ids=inputs.input_ids,\n",
    "    attention_mask=inputs.attention_mask,\n",
    "    max_new_tokens=1200,\n",
    "    use_cache=True\n",
    ")\n",
    "\n",
    "# Decode the generated output\n",
    "response = tokenizer.batch_decode(outputs)\n",
    "\n",
    "# Extract and print only the response part after \"### Response:\"\n",
    "result = response[0].split(\"### Response:\")[1]\n",
    "print(\"Generated Response:\")\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "massage_robot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
